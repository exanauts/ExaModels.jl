var documenterSearchIndex = {"docs":
[{"location":"dist/","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"EditURL = \"dist.jl\"","category":"page"},{"location":"dist/#Example:-Distillation-Column","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"","category":"section"},{"location":"dist/","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"function distillation_column_model(T = 3; backend = nothing)\n\n    NT = 30\n    FT = 17\n    Ac = 0.5\n    At = 0.25\n    Ar = 1.0\n    D = 0.2\n    F = 0.4\n    ybar = 0.8958\n    ubar = 2.0\n    alpha = 1.6\n    dt = 10 / T\n    xAf = 0.5\n    xA0s = ExaModels.convert_array([(i, 0.5) for i = 0:NT+1], backend)\n\n    itr0 = ExaModels.convert_array(collect(Iterators.product(1:T, 1:FT-1)), backend)\n    itr1 = ExaModels.convert_array(collect(Iterators.product(1:T, FT+1:NT)), backend)\n    itr2 = ExaModels.convert_array(collect(Iterators.product(0:T, 0:NT+1)), backend)\n\n    c = ExaCore(backend)\n\n    xA = variable(c, 0:T, 0:NT+1; start = 0.5)\n    yA = variable(c, 0:T, 0:NT+1; start = 0.5)\n    u = variable(c, 0:T; start = 1.0)\n    V = variable(c, 0:T; start = 1.0)\n    L2 = variable(c, 0:T; start = 1.0)\n\n    objective(c, (yA[t, 1] - ybar)^2 for t = 0:T)\n    objective(c, (u[t] - ubar)^2 for t = 0:T)\n\n    constraint(c, xA[0, i] - xA0 for (i, xA0) in xA0s)\n    constraint(\n        c,\n        (xA[t, 0] - xA[t-1, 0]) / dt - (1 / Ac) * (yA[t, 1] - xA[t, 0]) for t = 1:T\n    )\n    constraint(\n        c,\n        (xA[t, i] - xA[t-1, i]) / dt -\n        (1 / At) * (u[t] * D * (yA[t, i-1] - xA[t, i]) - V[t] * (yA[t, i] - yA[t, i+1])) for\n        (t, i) in itr0\n    )\n    constraint(\n        c,\n        (xA[t, FT] - xA[t-1, FT]) / dt -\n        (1 / At) * (\n            F * xAf + u[t] * D * xA[t, FT-1] - L2[t] * xA[t, FT] -\n            V[t] * (yA[t, FT] - yA[t, FT+1])\n        ) for t = 1:T\n    )\n    constraint(\n        c,\n        (xA[t, i] - xA[t-1, i]) / dt -\n        (1 / At) * (L2[t] * (yA[t, i-1] - xA[t, i]) - V[t] * (yA[t, i] - yA[t, i+1])) for\n        (t, i) in itr1\n    )\n    constraint(\n        c,\n        (xA[t, NT+1] - xA[t-1, NT+1]) / dt -\n        (1 / Ar) * (L2[t] * xA[t, NT] - (F - D) * xA[t, NT+1] - V[t] * yA[t, NT+1]) for\n        t = 1:T\n    )\n    constraint(c, V[t] - u[t] * D - D for t = 0:T)\n    constraint(c, L2[t] - u[t] * D - F for t = 0:T)\n    constraint(\n        c,\n        yA[t, i] * (1 - xA[t, i]) - alpha * xA[t, i] * (1 - yA[t, i]) for (t, i) in itr2\n    )\n\n    return ExaModel(c)\nend","category":"page"},{"location":"dist/","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"distillation_column_model (generic function with 2 methods)","category":"page"},{"location":"dist/","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"using ExaModels, NLPModelsIpopt\n\nm = distillation_column_model(10)\nipopt(m)","category":"page"},{"location":"dist/","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"dist/","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"","category":"page"},{"location":"dist/","page":"Example: Distillation Column","title":"Example: Distillation Column","text":"This page was generated using Literate.jl.","category":"page"},{"location":"develop/#Developing-Extensions","page":"Developing Extensions","title":"Developing Extensions","text":"","category":"section"},{"location":"develop/","page":"Developing Extensions","title":"Developing Extensions","text":"ExaModels.jl's API only uses simple julia funcitons, and thus, implementing the extensions is straightforward. Below, we suggest a good practice for implementing an extension package.","category":"page"},{"location":"develop/","page":"Developing Extensions","title":"Developing Extensions","text":"Let's say that we want to implement an extension package for the example problem in Getting Started. An extension package may look like:","category":"page"},{"location":"develop/","page":"Developing Extensions","title":"Developing Extensions","text":"Root\n├───Project.toml\n├── src\n│   └── LuksanVlcekModels.jl\n└── test\n    └── runtest.jl","category":"page"},{"location":"develop/","page":"Developing Extensions","title":"Developing Extensions","text":"Each of the files containing","category":"page"},{"location":"develop/","page":"Developing Extensions","title":"Developing Extensions","text":"# Project.toml\n\nname = \"LuksanVlcekModels\"\nuuid = \"0c5951a0-f777-487f-ad29-fac2b9a21bf1\"\nauthors = [\"Sungho Shin <sshin@anl.gov>\"]\nversion = \"0.1.0\"\n\n[deps]\nExaModels = \"1037b233-b668-4ce9-9b63-f9f681f55dd2\"\n\n[extras]\nNLPModelsIpopt = \"f4238b75-b362-5c4c-b852-0801c9a21d71\"\nTest = \"8dfed614-e22c-5e08-85e1-65c5234f0b40\"\n\n[targets]\ntest = [\"Test\", \"NLPModelsIpopt\"]","category":"page"},{"location":"develop/","page":"Developing Extensions","title":"Developing Extensions","text":"# src/LuksanVlcekModels.jl\n\nmodule LuksanVlcekModels\n\nimport ExaModels\n\nfunction luksan_vlcek_obj(x,i)\n    return 100*(x[i-1]^2-x[i])^2+(x[i-1]-1)^2\nend\n\nfunction luksan_vlcek_con(x,i)\n    return 3x[i+1]^3+2*x[i+2]-5+sin(x[i+1]-x[i+2])sin(x[i+1]+x[i+2])+4x[i+1]-x[i]exp(x[i]-x[i+1])-3\nend\n\nfunction luksan_vlcek_x0(i)\n    return mod(i,2)==1 ? -1.2 : 1.0\nend\n\nfunction luksan_vlcek_model(N; backend = nothing)\n    \n    c = ExaModels.ExaCore(backend)\n    x = ExaModels.variable(\n        c, N;\n        start = (luksan_vlcek_x0(i) for i=1:N)\n    )\n    ExaModels.constraint(\n        c,\n        luksan_vlcek_con(x,i)\n        for i in 1:N-2)\n    ExaModels.objective(c, luksan_vlcek_obj(x,i) for i in 2:N)\n    \n    return ExaModels.ExaModel(c) # returns the model\nend\n\nexport luksan_vlcek_model\n\nend # module LuksanVlcekModels","category":"page"},{"location":"develop/","page":"Developing Extensions","title":"Developing Extensions","text":"# test/runtest.jl\n\nusing Test, LuksanVlcekModels, NLPModelsIpopt\n\n@testset \"LuksanVlcekModelsTest\" begin\n    m = luksan_vlcek_model(10)\n    result = ipopt(m)\n\n    @test result.status == :first_order\n    @test result.solution ≈ [\n        -0.9505563573613093\n        0.9139008176388945\n        0.9890905176644905\n        0.9985592422681151\n        0.9998087408802769\n        0.9999745932450963\n        0.9999966246997642\n        0.9999995512524277\n        0.999999944919307\n        0.999999930070643\n    ]\n    @test result.multipliers ≈ [\n        4.1358568305002255\n        -1.876494903703342\n        -0.06556333356358675\n        -0.021931863018312875\n        -0.0019537261317119302\n        -0.00032910445671233547\n        -3.8788212776372465e-5\n        -7.376592164341867e-6\n    ]\nend","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"EditURL = \"opf.jl\"","category":"page"},{"location":"opf/#Example:-Optimal-Power-Flow","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"","category":"section"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"function parse_ac_power_data(filename)\n    data = PowerModels.parse_file(filename)\n    PowerModels.standardize_cost_terms!(data, order=2)\n    PowerModels.calc_thermal_limits!(data)\n    ref = PowerModels.build_ref(data)[:it][:pm][:nw][0]\n\n    arcdict = Dict(\n        a=>k\n        for (k,a) in enumerate(ref[:arcs]))\n    busdict = Dict(\n        k=>i\n        for (i,(k,v)) in enumerate(ref[:bus]))\n    gendict = Dict(\n        k=>i\n        for (i,(k,v)) in enumerate(ref[:gen]))\n    branchdict = Dict(\n        k=>i\n        for (i,(k,v)) in enumerate(ref[:branch]))\n\n    return (\n        bus = [\n            begin\n                bus_loads = [ref[:load][l] for l in ref[:bus_loads][k]]\n                bus_shunts = [ref[:shunt][s] for s in ref[:bus_shunts][k]]\n                pd = sum(load[\"pd\"] for load in bus_loads; init = 0.)\n                gs = sum(shunt[\"gs\"] for shunt in bus_shunts; init = 0.)\n                qd = sum(load[\"qd\"] for load in bus_loads; init = 0.)\n                bs = sum(shunt[\"bs\"] for shunt in bus_shunts; init = 0.)\n                (\n                    i = busdict[k],\n                    pd = pd, gs = gs, qd = qd, bs = bs\n                )\n            end\n            for (k,v) in ref[:bus]],\n        gen = [\n            (i = gendict[k],\n             cost1 = v[\"cost\"][1], cost2 = v[\"cost\"][2], cost3 = v[\"cost\"][3], bus = busdict[v[\"gen_bus\"]])\n            for (k,v) in ref[:gen]],\n        arc =[\n            (i=k, rate_a = ref[:branch][l][\"rate_a\"], bus = busdict[i])\n            for (k,(l,i,j)) in enumerate(ref[:arcs])],\n        branch = [\n            begin\n                f_idx = arcdict[i, branch[\"f_bus\"], branch[\"t_bus\"]]\n                t_idx = arcdict[i, branch[\"t_bus\"], branch[\"f_bus\"]]\n                g, b = PowerModels.calc_branch_y(branch)\n                tr, ti = PowerModels.calc_branch_t(branch)\n                ttm = tr^2 + ti^2\n                g_fr = branch[\"g_fr\"]\n                b_fr = branch[\"b_fr\"]\n                g_to = branch[\"g_to\"]\n                b_to = branch[\"b_to\"]\n                c1 = (-g*tr-b*ti)/ttm\n                c2 = (-b*tr+g*ti)/ttm\n                c3 = (-g*tr+b*ti)/ttm\n                c4 = (-b*tr-g*ti)/ttm\n                c5 = (g+g_fr)/ttm\n                c6 = (b+b_fr)/ttm\n                c7 = (g+g_to)\n                c8 = (b+b_to)\n                (\n                    i = branchdict[i],\n                    j = 1,\n                    f_idx = f_idx,\n                    t_idx = t_idx,\n                    f_bus = busdict[branch[\"f_bus\"]],\n                    t_bus = busdict[branch[\"t_bus\"]],\n                    c1 = c1,\n                    c2 = c2,\n                    c3 = c3,\n                    c4 = c4,\n                    c5 = c5,\n                    c6 = c6,\n                    c7 = c7,\n                    c8 = c8,\n                    rate_a_sq = branch[\"rate_a\"]^2,\n                )\n            end\n            for (i,branch) in ref[:branch]],\n        ref_buses = [busdict[i] for (i,k) in ref[:ref_buses]],\n        vmax = [\n            v[\"vmax\"] for (k,v) in ref[:bus]],\n        vmin = [\n            v[\"vmin\"] for (k,v) in ref[:bus]],\n        pmax = [\n            v[\"pmax\"] for (k,v) in ref[:gen]],\n        pmin = [\n            v[\"pmin\"] for (k,v) in ref[:gen]],\n        qmax = [\n            v[\"qmax\"] for (k,v) in ref[:gen]],\n        qmin = [\n            v[\"qmin\"] for (k,v) in ref[:gen]],\n        rate_a =[\n            ref[:branch][l][\"rate_a\"]\n            for (k,(l,i,j)) in enumerate(ref[:arcs])],\n        angmax = [b[\"angmax\"] for (i,b) in ref[:branch]],\n        angmin = [b[\"angmin\"] for (i,b) in ref[:branch]],\n    )\nend\n\nconvert_data(data::N, backend) where {names, N <: NamedTuple{names}} = NamedTuple{names}(ExaModels.convert_array(d,backend) for d in data)\n\nparse_ac_power_data(filename, backend) = convert_data(parse_ac_power_data(filename), backend)\n\nfunction ac_power_model(\n    filename;\n    backend = nothing,\n    T = Float64\n    )\n\n    data = parse_ac_power_data(filename, backend)\n\n    w = ExaCore(T, backend)\n\n    va = variable(\n        w, length(data.bus);\n    )\n\n    vm = variable(\n        w,\n        length(data.bus);\n        start = fill!(similar(data.bus,Float64),1.),\n        lvar = data.vmin,\n        uvar = data.vmax\n    )\n    pg = variable(\n        w,\n        length(data.gen);\n        lvar = data.pmin,\n        uvar = data.pmax\n    )\n\n    qg = variable(\n        w,\n        length(data.gen);\n        lvar = data.qmin,\n        uvar = data.qmax\n    )\n\n    p = variable(\n        w,\n        length(data.arc);\n        lvar = -data.rate_a,\n        uvar = data.rate_a\n    )\n\n    q = variable(\n        w,\n        length(data.arc);\n        lvar = -data.rate_a,\n        uvar = data.rate_a\n    )\n\n    o = objective(\n        w,\n        g.cost1 * pg[g.i]^2 + g.cost2 * pg[g.i] + g.cost3\n        for g in data.gen)\n\n    c1 = constraint(\n        w,\n        va[i] for i in data.ref_buses)\n\n    c2 = constraint(\n        w,\n        p[b.f_idx]\n        - b.c5*vm[b.f_bus]^2\n        - b.c3*(vm[b.f_bus]*vm[b.t_bus]*cos(va[b.f_bus]-va[b.t_bus]))\n        - b.c4*(vm[b.f_bus]*vm[b.t_bus]*sin(va[b.f_bus]-va[b.t_bus]))\n        for b in data.branch)\n\n    c3 = constraint(\n        w,\n        q[b.f_idx]\n        + b.c6*vm[b.f_bus]^2\n        + b.c4*(vm[b.f_bus]*vm[b.t_bus]*cos(va[b.f_bus]-va[b.t_bus]))\n        - b.c3*(vm[b.f_bus]*vm[b.t_bus]*sin(va[b.f_bus]-va[b.t_bus]))\n        for b in data.branch)\n\n    c4 = constraint(\n        w,\n        p[b.t_idx]\n        - b.c7*vm[b.t_bus]^2\n        - b.c1*(vm[b.t_bus]*vm[b.f_bus]*cos(va[b.t_bus]-va[b.f_bus]))\n        - b.c2*(vm[b.t_bus]*vm[b.f_bus]*sin(va[b.t_bus]-va[b.f_bus]))\n        for b in data.branch)\n\n    c5 = constraint(\n        w,\n        q[b.t_idx]\n        + b.c8*vm[b.t_bus]^2\n        + b.c2*(vm[b.t_bus]*vm[b.f_bus]*cos(va[b.t_bus]-va[b.f_bus]))\n        - b.c1*(vm[b.t_bus]*vm[b.f_bus]*sin(va[b.t_bus]-va[b.f_bus]))\n        for b in data.branch)\n\n    c6 = constraint(\n        w,\n        va[b.f_bus] - va[b.t_bus] for b in data.branch;\n            lcon = data.angmin,\n            ucon = data.angmax\n            )\n    c7 = constraint(\n        w,\n        p[b.f_idx]^2 + q[b.f_idx]^2 - b.rate_a_sq for b in data.branch;\n            lcon = fill!(similar(data.branch,Float64,length(data.branch)),-Inf)\n            )\n    c8 = constraint(\n        w,\n        p[b.t_idx]^2 + q[b.t_idx]^2 - b.rate_a_sq for b in data.branch;\n            lcon = fill!(similar(data.branch,Float64,length(data.branch)),-Inf)\n            )\n\n    c9 = constraint(\n        w,\n        + b.pd\n        + b.gs * vm[b.i]^2\n        for b in data.bus)\n\n    c10 = constraint(\n        w,\n        + b.qd\n        - b.bs * vm[b.i]^2\n        for b in data.bus)\n\n    c11 = constraint!(\n        w,\n        c9,\n        a.bus => p[a.i]\n        for a in data.arc)\n    c12 = constraint!(\n        w,\n        c10,\n        a.bus => q[a.i]\n        for a in data.arc)\n\n    c13 = constraint!(\n        w,\n        c9,\n        g.bus =>-pg[g.i]\n        for g in data.gen)\n    c14 = constraint!(\n        w,\n        c10,\n        g.bus =>-qg[g.i]\n        for g in data.gen)\n\n    return ExaModel(w)\n\nend","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"ac_power_model (generic function with 1 method)","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"We first download the case file.","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"using Downloads\n\ncase = tempname() * \".m\"\n\nDownloads.download(\n    \"https://raw.githubusercontent.com/power-grid-lib/pglib-opf/dc6be4b2f85ca0e776952ec22cbd4c22396ea5a3/pglib_opf_case3_lmbd.m\",\n    case\n)","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"\"/tmp/jl_BgJc12xOvU.m\"","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"Then, we can model/sovle the problem.","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"using PowerModels, ExaModels, NLPModelsIpopt\n\nm = ac_power_model(case)\nipopt(m)","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"","category":"page"},{"location":"opf/","page":"Example: Optimal Power Flow","title":"Example: Optimal Power Flow","text":"This page was generated using Literate.jl.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"EditURL = \"performance.jl\"","category":"page"},{"location":"performance/#Performance-Tips","page":"Performance Tips","title":"Performance Tips","text":"","category":"section"},{"location":"performance/#Use-a-function-to-create-a-model","page":"Performance Tips","title":"Use a function to create a model","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"It is always better to use functions to create ExaModels. This in this way, the functions used for specifing objective/constraint functions are not recreated over all over, and thus, we can take advantage of the previously compiled model creation code. Let's consider the following example.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"using ExaModels\n\nt = @elapsed begin\n    c = ExaCore()\n    N = 10\n    x = variable(c, N; start = (mod(i, 2) == 1 ? -1.2 : 1.0 for i = 1:N))\n    objective(c, 100 * (x[i-1]^2 - x[i])^2 + (x[i-1] - 1)^2 for i = 2:N)\n    constraint(\n        c,\n        3x[i+1]^3 + 2 * x[i+2] - 5 + sin(x[i+1] - x[i+2])sin(x[i+1] + x[i+2]) + 4x[i+1] -\n            x[i]exp(x[i] - x[i+1]) - 3 for i = 1:N-2\n                )\n    m = ExaModel(c)\nend\n\nprintln(\"$t seconds elapsed\")","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"0.156983181 seconds elapsed\n","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Even at the second call,","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"t = @elapsed begin\n    c = ExaCore()\n    N = 10\n    x = variable(c, N; start = (mod(i, 2) == 1 ? -1.2 : 1.0 for i = 1:N))\n    objective(c, 100 * (x[i-1]^2 - x[i])^2 + (x[i-1] - 1)^2 for i = 2:N)\n    constraint(\n        c,\n        3x[i+1]^3 + 2 * x[i+2] - 5 + sin(x[i+1] - x[i+2])sin(x[i+1] + x[i+2]) + 4x[i+1] -\n            x[i]exp(x[i] - x[i+1]) - 3 for i = 1:N-2\n                )\n    m = ExaModel(c)\nend\n\nprintln(\"$t seconds elapsed\")","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"0.136859494 seconds elapsed\n","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"the model creation time can be slightly reduced but the compilation time is still quite significant.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"But instead, if you create a function, we can significantly reduce the model creation time.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"function luksan_vlcek_model(N)\n    c = ExaCore()\n    x = variable(c, N; start = (mod(i, 2) == 1 ? -1.2 : 1.0 for i = 1:N))\n    objective(c, 100 * (x[i-1]^2 - x[i])^2 + (x[i-1] - 1)^2 for i = 2:N)\n    constraint(\n        c,\n        3x[i+1]^3 + 2 * x[i+2] - 5 + sin(x[i+1] - x[i+2])sin(x[i+1] + x[i+2]) + 4x[i+1] -\n            x[i]exp(x[i] - x[i+1]) - 3 for i = 1:N-2\n                )\n    m = ExaModel(c)\nend\n\nt = @elapsed luksan_vlcek_model(N)\nprintln(\"$t seconds elapsed\")","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"0.227306393 seconds elapsed\n","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"t = @elapsed luksan_vlcek_model(N)\nprintln(\"$t seconds elapsed\")","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"0.000105046 seconds elapsed\n","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"So, the model creation time can be essentially nothing. Thus, if you care about the model creation time, always make sure to write a function for creating the model, and do not directly create a model from the REPL.","category":"page"},{"location":"performance/#Make-sure-your-array's-eltype-is-concrete","page":"Performance Tips","title":"Make sure your array's eltype is concrete","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"In order for ExaModels to run for loops over the array you provided without any overhead caused by type inference, the eltype of the data array should always be a concrete type. Furthermore, this is required if you want to run ExaModels on GPU accelerators.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Let's take an example.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"using ExaModels\n\nN = 1000\n\nfunction luksan_vlcek_model_concrete(N)\n    c = ExaCore()\n\n    arr1 = Array(2:N)\n    arr2 = Array(1:N-2)\n\n    x = variable(c, N; start = (mod(i, 2) == 1 ? -1.2 : 1.0 for i = 1:N))\n    objective(c, 100 * (x[i-1]^2 - x[i])^2 + (x[i-1] - 1)^2 for i = arr1)\n    constraint(\n        c,\n        3x[i+1]^3 + 2 * x[i+2] - 5 + sin(x[i+1] - x[i+2])sin(x[i+1] + x[i+2]) + 4x[i+1] -\n            x[i]exp(x[i] - x[i+1]) - 3 for i = arr2\n                )\n    m = ExaModel(c)\nend\n\nfunction luksan_vlcek_model_non_concrete(N)\n    c = ExaCore()\n\n    arr1 = Array{Any}(2:N)\n    arr2 = Array{Any}(1:N-2)\n\n    x = variable(c, N; start = (mod(i, 2) == 1 ? -1.2 : 1.0 for i = 1:N))\n    objective(c, 100 * (x[i-1]^2 - x[i])^2 + (x[i-1] - 1)^2 for i = arr1)\n    constraint(\n        c,\n        3x[i+1]^3 + 2 * x[i+2] - 5 + sin(x[i+1] - x[i+2])sin(x[i+1] + x[i+2]) + 4x[i+1] -\n            x[i]exp(x[i] - x[i+1]) - 3 for i = arr2\n                )\n    m = ExaModel(c)\nend","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"luksan_vlcek_model_non_concrete (generic function with 1 method)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Here, observe that","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"isconcretetype(eltype(Array(2:N)))","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"true","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"isconcretetype(eltype(Array{Any}(2:N)))","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"false","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"As you can see, the first array type has concrete eltypes, whereas the second array type has non concrete eltypes. Due to this, the array stored in the model created by luksan_vlcek_model_non_concrete will have non-concrete eltypes.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Now let's compare the performance. We will use the following benchmark function here.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"using NLPModels\n\nfunction benchmark_callbacks(m; N = 100)\n    nvar = m.meta.nvar\n    ncon = m.meta.ncon\n    nnzj = m.meta.nnzj\n    nnzh = m.meta.nnzh\n\n    x = copy(m.meta.x0)\n    y = similar(m.meta.x0, ncon)\n    c = similar(m.meta.x0, ncon)\n    g = similar(m.meta.x0, nvar)\n    jac = similar(m.meta.x0, nnzj)\n    hess = similar(m.meta.x0, nnzh)\n    jrows = similar(m.meta.x0, Int, nnzj)\n    jcols = similar(m.meta.x0, Int, nnzj)\n    hrows = similar(m.meta.x0, Int, nnzh)\n    hcols = similar(m.meta.x0, Int, nnzh)\n\n    GC.enable(false)\n\n    NLPModels.obj(m, x) # to compile\n\n    tobj = (1 / N) * @elapsed for t = 1:N\n        NLPModels.obj(m, x)\n    end\n\n    NLPModels.cons!(m, x, c) # to compile\n    tcon = (1 / N) * @elapsed for t = 1:N\n        NLPModels.cons!(m, x, c)\n    end\n\n    NLPModels.grad!(m, x, g) # to compile\n    tgrad = (1 / N) * @elapsed for t = 1:N\n        NLPModels.grad!(m, x, g)\n    end\n\n    NLPModels.jac_coord!(m, x, jac) # to compile\n    tjac = (1 / N) * @elapsed for t = 1:N\n        NLPModels.jac_coord!(m, x, jac)\n    end\n\n    NLPModels.hess_coord!(m, x, y, hess) # to compile\n    thess = (1 / N) * @elapsed for t = 1:N\n        NLPModels.hess_coord!(m, x, y, hess)\n    end\n\n    NLPModels.jac_structure!(m, jrows, jcols) # to compile\n    tjacs = (1 / N) * @elapsed for t = 1:N\n        NLPModels.jac_structure!(m, jrows, jcols)\n    end\n\n    NLPModels.hess_structure!(m, hrows, hcols) # to compile\n    thesss = (1 / N) * @elapsed for t = 1:N\n        NLPModels.hess_structure!(m, hrows, hcols)\n    end\n\n    GC.enable(true)\n\n    return (\n        tobj = tobj,\n        tcon = tcon,\n        tgrad = tgrad,\n        tjac = tjac,\n        thess = thess,\n        tjacs = tjacs,\n        thesss = thesss,\n    )\nend","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"benchmark_callbacks (generic function with 1 method)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"The performance comparison is here:","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"m1 = luksan_vlcek_model_concrete(N)\nm2 = luksan_vlcek_model_non_concrete(N)\n\nbenchmark_callbacks(m1)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"(tobj = 1.729097e-5, tcon = 2.851414e-5, tgrad = 2.0792620000000003e-5, tjac = 5.180206e-5, thess = 0.00047541703, tjacs = 1.9449459999999998e-5, thesss = 2.363522e-5)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"benchmark_callbacks(m2)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"(tobj = 0.0001980114, tcon = 0.00026012355, tgrad = 0.00025958216, tjac = 0.0015130951600000001, thess = 0.0037774603699999997, tjacs = 0.00052794032, thesss = 0.0021484905400000003)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"As can be seen here, having concrete eltype dramatically improves the performance. This is because when all the data arrays' eltypes are concrete, the AD evaluations can be performed without any type inferernce, and this should be as fast as highly optimized C/C++/Fortran code.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"When you're using GPU accelerators, the eltype of the array should always be concrete. In fact, non-concrete etlype will already cause an error when creating the array. For example,","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"using CUDA\n\ntry\n    arr1 = CuArray(Array{Any}(2:N))\ncatch e\n    showerror(stdout,e)\nend","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"CuArray only supports element types that are allocated inline.\nAny is not allocated inline\n","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"This page was generated using Literate.jl.","category":"page"},{"location":"quad/","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"EditURL = \"quad.jl\"","category":"page"},{"location":"quad/#Example:-Quadrotor","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"","category":"section"},{"location":"quad/","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"function quadrotor_model(N = 3; backend = nothing)\n\n    n = 9\n    p = 4\n    nd= 9\n    d(i,j,N) = (j==1 ? 1*sin(2*pi/N*i) : 0.) + (j==3 ? 2*sin(4*pi/N*i) : 0.) + (j==5 ? 2*i/N : 0.)\n    dt = .01\n    R = fill(1/10,4)\n    Q = [1,0,1,0,1,0,1,1,1]\n    Qf= [1,0,1,0,1,0,1,1,1]/dt\n\n    x0s  = [(i,0.) for i=1:n]\n    itr0 = [(i,j,R[j]) for (i,j) in Base.product(1:N,1:p)]\n    itr1 = [(i,j,Q[j],d(i,j,N)) for (i,j) in Base.product(1:N,1:n)]\n    itr2 = [(j,Qf[j],d(N+1,j,N)) for j in 1:n]\n\n    c = ExaCore(backend)\n\n    x= variable(c,1:N+1,1:n)\n    u= variable(c,1:N,1:p);\n\n    constraint(c, x[1,i]-x0 for (i,x0) in x0s)\n    constraint(c, -x[i+1,1] + x[i,1] + (x[i,2])*dt for i=1:N)\n    constraint(c, -x[i+1,2] + x[i,2] + (u[i,1]*cos(x[i,7])*sin(x[i,8])*cos(x[i,9])+u[i,1]*sin(x[i,7])*sin(x[i,9]))*dt for i=1:N)\n    constraint(c, -x[i+1,3] + x[i,3] + (x[i,4])*dt for i=1:N)\n    constraint(c, -x[i+1,4] + x[i,4] + (u[i,1]*cos(x[i,7])*sin(x[i,8])*sin(x[i,9])-u[i,1]*sin(x[i,7])*cos(x[i,9]))*dt for i=1:N)\n    constraint(c, -x[i+1,5] + x[i,5] + (x[i,6])*dt for i=1:N)\n    constraint(c, -x[i+1,6] + x[i,6] + (u[i,1]*cos(x[i,7])*cos(x[i,8])-9.8)*dt for i=1:N)\n    constraint(c, -x[i+1,7] + x[i,7] + (u[i,2]*cos(x[i,7])/cos(x[i,8])+u[i,3]*sin(x[i,7])/cos(x[i,8]))*dt for i=1:N)\n    constraint(c, -x[i+1,8] + x[i,8] + (-u[i,2]*sin(x[i,7])+u[i,3]*cos(x[i,7]))*dt for i=1:N)\n    constraint(c, -x[i+1,9] + x[i,9] + (u[i,2]*cos(x[i,7])*tan(x[i,8])+u[i,3]*sin(x[i,7])*tan(x[i,8])+u[i,4])*dt for i=1:N)\n\n    objective(c, .5*R*(u[i,j]^2) for (i,j,R) in itr0)\n    objective(c, .5*Q*(x[i,j]-d)^2 for (i,j,Q,d) in itr1)\n    objective(c, .5*Qf*(x[N+1,j]-d)^2 for (j,Qf,d) in itr2)\n\n    m = ExaModel(c)\n\nend","category":"page"},{"location":"quad/","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"quadrotor_model (generic function with 2 methods)","category":"page"},{"location":"quad/","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"using ExaModels, NLPModelsIpopt\n\nm = quadrotor_model(100)\nresult = ipopt(m)","category":"page"},{"location":"quad/","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"quad/","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"","category":"page"},{"location":"quad/","page":"Example: Quadrotor","title":"Example: Quadrotor","text":"This page was generated using Literate.jl.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"EditURL = \"guide.jl\"","category":"page"},{"location":"guide/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"ExaModels can create nonlinear prgogramming models and allows solving the created models using NLP solvers (in particular, those that are interfaced with NLPModels, such as NLPModelsIpopt and MadNLP. This documentation page will describe how to use ExaModels to model and solve nonlinear optimization problems.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"We will first consider the following simple nonlinear program [3]:","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"beginaligned\nmin_x_i_i=0^N sum_i=2^N  100(x_i-1^2-x_i)^2+(x_i-1-1)^2\ntextst   3x_i+1^3+2x_i+2-5+sin(x_i+1-x_i+2)sin(x_i+1+x_i+2)+4x_i+1-x_i e^x_i-x_i+1-3 = 0\nendaligned","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"We will follow the following Steps to create the model/solve this optimization problem.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Step 0: import ExaModels.jl\nStep 1: create a ExaCore object, wherein we can progressively build an optimization model.\nStep 2: create optimization variables with variable, while attaching it to previously created ExaCore.\nStep 3 (interchangable with Step 3): create objective function with objective, while attaching it to previously created ExaCore.\nStep 4 (interchangable with Step 2): create constraints with constraint, while attaching it to previously created ExaCore.\nStep 5: create an ExaModel based on the ExaCore.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Now, let's jump right in. We import ExaModels via (Step 0):","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"using ExaModels","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Now, all the functions that are necessary for creating model are imported to into Main.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"An ExaCore object can be created simply by (Step 1):","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"c = ExaCore()","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"An ExaCore\n\n  Float type: ...................... Float64\n  Array type: ...................... Vector{Float64}\n  Backend: ......................... Nothing\n\n  number of objective patterns: .... 0\n  number of constraint patterns: ... 0\n","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"This is where our optimziation model information will be progressively stored. This object is not yet an NLPModel, but it will essentially store all the necessary information.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Now, let's create the optimziation variables. From the problem definition, we can see that we will need N scalar variables. We will choose N=10, and create the variable xinmathbbR^N with the follwoing command:","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"N = 10\nx = variable(c, N; start = (mod(i, 2) == 1 ? -1.2 : 1.0 for i = 1:N))","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Variable\n\n  x ∈ R^{10}\n","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"This creates the variable x, which we will be able to refer to when we create constraints/objective constraionts. Also, this modifies the information in the ExaCore object properly so that later an optimization model can be properly created with the necessary information. Observe that we have used the keyword argument start to specify the initial guess for the solution. The variable upper and lower bounds can be specified in a similar manner.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"The objective can be set as follows:","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"objective(c, 100 * (x[i-1]^2 - x[i])^2 + (x[i-1] - 1)^2 for i = 2:N)","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"\nObjective\n\n  min (...) + ∑_{p ∈ P} f(x,p)\n\n  where |P| = 9\n","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"The constraints can be set as follows:","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"constraint(\n    c,\n    3x[i+1]^3 + 2 * x[i+2] - 5 + sin(x[i+1] - x[i+2])sin(x[i+1] + x[i+2]) + 4x[i+1] -\n    x[i]exp(x[i] - x[i+1]) - 3 for i = 1:N-2\n)","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"\nConstraint\n\n  s.t. (...)\n       g♭ ≤ [g(x,p)]_{p ∈ P} ≤ g♯\n\n  where |P| = 8\n","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Finally, we are ready to create an ExaModel from the data we have collected in ExaCore. Since ExaCore includes all the necessary information, we can do this simply by:","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"m = ExaModel(c)","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"An ExaModel\n\n  Problem name: Generic\n   All variables: ████████████████████ 10     All constraints: ████████████████████ 8     \n            free: ████████████████████ 10                free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ████████████████████ 8     \n          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n            nnzh: (-36.36% sparsity)   75              linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n                                                    nonlinear: ████████████████████ 8     \n                                                         nnzj: ( 70.00% sparsity)   24    \n\n","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Now, we got an optimization model ready to be solved. This problem can be solved with for example, with the Ipopt solver, as follows.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"using NLPModelsIpopt\nresult = ipopt(m)","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Here, result is an AbstractExecutionStats, which typically contains the solution information. We can check several information as follows.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"println(\"Status: $(result.status)\")\nprintln(\"Number of iterations: $(result.iter)\")","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Status: first_order\nNumber of iterations: 6\n","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"The solution values for variable x can be inquired by:","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"sol = solution(result, x)","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"10-element view(::Vector{Float64}, 1:10) with eltype Float64:\n -0.9505563573613093\n  0.9139008176388945\n  0.9890905176644905\n  0.9985592422681151\n  0.9998087408802769\n  0.9999745932450963\n  0.9999966246997642\n  0.9999995512524277\n  0.999999944919307\n  0.999999930070643","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"ExaModels provide several APIs similar to this:","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"solution inquires the primal solution.\nmultiplier inquires the dual solution.\nmultiplier_L inquires the lower bound dual solution.\nmultiplier_U inquires the upper bound dual solution.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"This concludes a short tutorial on how to use ExaModels to model and solve optimization problems. Want to learn more? Take a look at the following examples, which provide further tutorial on how to use ExaModels.jl. Each of the examples are designed to instruct a few additional techniques.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"Example: Quadrotor: modeling multiple types of objective values and constraints.\nExample: Distillation Column: using two-dimensional index sets for variables.\nExample: Optimal Power Flow: handling complex data and using constraint augmentation.","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"","category":"page"},{"location":"guide/","page":"Getting Started","title":"Getting Started","text":"This page was generated using Literate.jl.","category":"page"},{"location":"core/#ExaModels","page":"API Manual","title":"ExaModels","text":"","category":"section"},{"location":"core/","page":"API Manual","title":"API Manual","text":"Modules = [ExaModels]","category":"page"},{"location":"core/#ExaModels.ExaModels","page":"API Manual","title":"ExaModels.ExaModels","text":"ExaModels\n\nAn algebraic modeling and automatic differentiation tool in Julia Language, specialized for SIMD abstraction of nonlinear programs.\n\nFor more information, please visit https://github.com/sshin23/ExaModels.jl\n\n\n\n\n\n","category":"module"},{"location":"core/#ExaModels.ExaModel-Tuple{C} where C<:ExaCore","page":"API Manual","title":"ExaModels.ExaModel","text":"ExaModel(core)\n\nReturns an ExaModel object, which can be solved by nonlinear optimization solvers within JuliaSmoothOptimizer ecosystem, such as NLPModelsIpopt or MadNLP.\n\nExample\n\njulia> using ExaModels\n\njulia> c = ExaCore();                      # create an ExaCore object\n\njulia> x = variable(c, 1:10);              # create variables\n\njulia> objective(c, x[i]^2 for i in 1:10); # set objective function\n\njulia> m = ExaModel(c)                     # creat an ExaModel object\nAn ExaModel\n\n  Problem name: Generic\n   All variables: ████████████████████ 10     All constraints: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n            free: ████████████████████ 10                free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n            nnzh: ( 81.82% sparsity)   10              linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n                                                    nonlinear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0\n                                                         nnzj: (------% sparsity)\n\njulia> using NLPModelsIpopt\n\njulia> result = ipopt(m; print_level=0)    # solve the problem\n\"Execution stats: first-order stationary\"\n\n\n\n\n\n\n","category":"method"},{"location":"core/#ExaModels.constraint-Union{Tuple{C}, Tuple{T}, Tuple{C, Base.Generator}} where {T, C<:(ExaCore{T, VT} where VT<:AbstractVector{T})}","page":"API Manual","title":"ExaModels.constraint","text":"constraint(core, generator; start = 0, lcon = 0,  ucon = 0)\n\nAdds constraints specified by a generator to core, and returns an Constraint object. \n\nKeyword Arguments\n\nstart: The initial guess of the solution. Can either be Number, AbstractArray, or Generator.\nlcon : The constraint lower bound. Can either be Number, AbstractArray, or Generator.\nucon : The constraint upper bound. Can either be Number, AbstractArray, or Generator.\n\nExample\n\njulia> using ExaModels\n\njulia> c = ExaCore();\n\njulia> x = variable(c, 10);\n\njulia> constraint(c, x[i] + x[i+1] for i=1:9; lcon = -1, ucon = (1+i for i=1:9))\nConstraint\n\n  s.t. (...)\n       g♭ ≤ [g(x,p)]_{p ∈ P} ≤ g♯\n\n  where |P| = 9\n\n\n\n\n\n","category":"method"},{"location":"core/#ExaModels.multipliers-Tuple{SolverCore.AbstractExecutionStats, ExaModels.Constraint}","page":"API Manual","title":"ExaModels.multipliers","text":"multipliers(result, y)\n\nReturns the multipliers for constraints y associated with result, obtained by solving the model.\n\nExample\n\njulia> using ExaModels, NLPModelsIpopt\n\njulia> c = ExaCore();                     \n\njulia> x = variable(c, 1:10, lvar = -1, uvar = 1);\n\njulia> objective(c, (x[i]-2)^2 for i in 1:10);\n\njulia> y = constraint(c, x[i] + x[i+1] for i=1:9; lcon = -1, ucon = (1+i for i=1:9));\n\njulia> m = ExaModel(c);                   \n\njulia> result = ipopt(m; print_level=0);\n\njulia> val = multipliers(result, y);\n\n\njulia> val[1] ≈ 0.81933930\ntrue\n\n\n\n\n\n","category":"method"},{"location":"core/#ExaModels.multipliers_L-Tuple{SolverCore.AbstractExecutionStats, Any}","page":"API Manual","title":"ExaModels.multipliers_L","text":"multipliers_L(result, x)\n\nReturns the multipliers_L for variable x associated with result, obtained by solving the model.\n\nExample\n\njulia> using ExaModels, NLPModelsIpopt\n\njulia> c = ExaCore();                     \n\njulia> x = variable(c, 1:10, lvar = -1, uvar = 1);\n\njulia> objective(c, (x[i]-2)^2 for i in 1:10);\n\njulia> m = ExaModel(c);                   \n\njulia> result = ipopt(m; print_level=0);\n\njulia> val = multipliers_L(result, x);\n\njulia> isapprox(val, fill(0, 10), atol=sqrt(eps(Float64)), rtol=Inf)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"core/#ExaModels.multipliers_U-Tuple{SolverCore.AbstractExecutionStats, Any}","page":"API Manual","title":"ExaModels.multipliers_U","text":"multipliers_U(result, x)\n\nReturns the multipliers_U for variable x associated with result, obtained by solving the model.\n\nExample\n\njulia> using ExaModels, NLPModelsIpopt\n\njulia> c = ExaCore();                     \n\njulia> x = variable(c, 1:10, lvar = -1, uvar = 1);\n\njulia> objective(c, (x[i]-2)^2 for i in 1:10);\n\njulia> m = ExaModel(c);                   \n\njulia> result = ipopt(m; print_level=0);\n\njulia> val = multipliers_U(result, x);\n\njulia> isapprox(val, fill(2, 10), atol=sqrt(eps(Float64)), rtol=Inf)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"core/#ExaModels.objective-Union{Tuple{C}, Tuple{C, Any}} where C<:ExaCore","page":"API Manual","title":"ExaModels.objective","text":"objective(core::ExaCore, generator)\n\nAdds objective terms specified by a generator to core, and returns an Objective object. \n\nExample\n\njulia> using ExaModels\n\njulia> c = ExaCore();\n\njulia> x = variable(c, 10);\n\njulia> objective(c, x[i]^2 for i=1:10)\nObjective\n\n  min (...) + ∑_{p ∈ P} f(x,p)\n\n  where |P| = 10\n\n\n\n\n\n","category":"method"},{"location":"core/#ExaModels.solution-Tuple{SolverCore.AbstractExecutionStats, Any}","page":"API Manual","title":"ExaModels.solution","text":"solution(result, x)\n\nReturns the solution for variable x associated with result, obtained by solving the model.\n\nExample\n\njulia> using ExaModels, NLPModelsIpopt\n\njulia> c = ExaCore();                     \n\njulia> x = variable(c, 1:10, lvar = -1, uvar = 1);\n\njulia> objective(c, (x[i]-2)^2 for i in 1:10);\n\njulia> m = ExaModel(c);                   \n\njulia> result = ipopt(m; print_level=0);\n\njulia> val = solution(result, x);\n\njulia> isapprox(val, fill(1, 10), atol=sqrt(eps(Float64)), rtol=Inf)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"core/#ExaModels.variable-Union{Tuple{C}, Tuple{T}, Tuple{C, Vararg{Any}}} where {T, C<:(ExaCore{T, VT} where VT<:AbstractVector{T})}","page":"API Manual","title":"ExaModels.variable","text":"variable(core, dims...; start = 0, lvar = -Inf, uvar = Inf)\n\nAdds variables with dimensions specified by dims to core, and returns Variable object. dims can be either Integer or UnitRange.\n\nKeyword Arguments\n\nstart: The initial guess of the solution. Can either be Number, AbstractArray, or Generator.\nlvar : The variable lower bound. Can either be Number, AbstractArray, or Generator.\nuvar : The variable upper bound. Can either be Number, AbstractArray, or Generator.\n\nExample\n\njulia> using ExaModels\n\njulia> c = ExaCore();\n\njulia> x = variable(c, 10; start = (sin(i) for i=1:10))\nVariable\n\n  x ∈ R^{10}\n\njulia> y = variable(c, 2:10, 3:5; lvar = zeros(9,3), uvar = ones(9,3))\nVariable\n\n  x ∈ R^{9 × 3}\n\n\n\n\n\n\n","category":"method"},{"location":"highlights/#Highlights","page":"Highlights","title":"Highlights","text":"","category":"section"},{"location":"highlights/#Key-differences-from-other-algebraic-modeling-tools","page":"Highlights","title":"Key differences from other algebraic modeling tools","text":"","category":"section"},{"location":"highlights/","page":"Highlights","title":"Highlights","text":"ExaModels.jl is different from other algebraic modeling tools, such as JuMP or AMPL, in the following ways:","category":"page"},{"location":"highlights/","page":"Highlights","title":"Highlights","text":"Modeling Interface: ExaModels.jl enforces users to specify the model equations always in the form of Generator. This allows ExaModels.jl to preserve the SIMD-compatible structure in the model equations.\nPerformance: ExaModels.jl compiles (via Julia's compiler) derivative evaluation codes that are specific to each computation pattern, based on reverse-mode automatic differentiation. This makes the speed of derivative evaluation (even on the CPU) significantly faster than other existing tools.\nPortability: ExaModels.jl can evaluate derivatives on GPU accelerators. The code is currently only tested for NVIDIA GPUs, but GPU code is implemented mostly based on the portable programming paradigm, KernelAbstractions.jl. In the future, we are interested in supporting Intel, AMD, and Apple GPUs.","category":"page"},{"location":"highlights/#Performance","page":"Highlights","title":"Performance","text":"","category":"section"},{"location":"highlights/","page":"Highlights","title":"Highlights","text":"For the nonlinear optimization problems that are suitable for SIMD abstraction, ExaModels.jl greatly accelerate the performance of derivative evaluations. The following is a recent benchmark result. Remarkably, for the AC OPF problem for a 9241 bus system, derivative evalution using ExaModels.jl on GPUs can be up to 2 orders of magnitudes faster than JuMP or AMPL.","category":"page"},{"location":"highlights/","page":"Highlights","title":"Highlights","text":"==============================================================\n|                 Evaluation Wall Time (sec)                 |\n==============================================================\n|      |           |           ExaModels (single)            |\n| case | nvar ncon |   obj     con    grad     jac    hess   |\n==============================================================\n|  LV1 | 100   98  | 6.3e-06 7.6e-06 6.3e-06 1.2e-05 9.3e-05 |\n|  LV2 |   1k 998  | 2.8e-05 3.0e-05 2.4e-05 5.5e-05 6.7e-04 |\n|  LV3 |  10k  10k | 2.8e-04 2.9e-04 2.3e-04 5.4e-04 2.5e-03 |\n|  QR1 | 659  459  | 8.9e-06 1.0e-05 6.2e-06 1.9e-05 3.1e-05 |\n|  QR2 |   7k   5k | 5.7e-05 5.1e-05 4.1e-05 1.0e-04 2.1e-04 |\n|  QR3 |  65k  45k | 5.9e-04 5.4e-04 4.6e-04 1.2e-03 6.4e-03 |\n|  DC1 | 402  396  | 1.4e-06 4.9e-06 2.6e-06 6.4e-06 3.5e-05 |\n|  DC2 |   3k   3k | 2.0e-06 2.6e-05 6.2e-06 5.4e-05 9.7e-05 |\n|  DC3 |  34k  33k | 1.1e-05 2.4e-04 6.3e-05 5.3e-04 2.0e-03 |\n|  PF1 |   1k   2k | 2.0e-06 3.5e-05 2.3e-06 3.7e-05 3.4e-04 |\n|  PF2 |  11k  17k | 5.3e-06 3.1e-04 9.7e-06 3.2e-04 3.6e-03 |\n|  PF3 |  86k 131k | 1.9e-05 2.8e-03 1.2e-04 2.7e-03 2.0e-02 |\n==============================================================\n|      |           |           ExaModels (multli)            |\n| case | nvar ncon |   obj     con    grad     jac    hess   |\n==============================================================\n|  LV1 | 100   98  | 1.3e-05 1.5e-05 1.7e-05 1.6e-05 1.0e-04 |\n|  LV2 |   1k 998  | 4.3e-05 4.1e-05 4.8e-05 7.5e-05 2.4e-04 |\n|  LV3 |  10k  10k | 2.5e-04 2.2e-04 3.6e-04 5.1e-04 2.7e-03 |\n|  QR1 | 659  459  | 2.2e-05 4.8e-05 2.4e-05 5.8e-05 8.4e-05 |\n|  QR2 |   7k   5k | 2.5e-04 9.7e-05 2.6e-04 1.4e-04 6.5e-04 |\n|  QR3 |  65k  45k | 5.0e-04 1.2e-03 7.7e-04 2.0e-03 6.9e-03 |\n|  DC1 | 402  396  | 1.0e-05 3.7e-05 1.3e-05 3.9e-05 1.2e-04 |\n|  DC2 |   3k   3k | 9.0e-06 1.8e-04 2.0e-05 2.0e-04 2.7e-04 |\n|  DC3 |  34k  33k | 2.3e-05 4.3e-04 8.6e-05 8.2e-04 2.6e-03 |\n|  PF1 |   1k   2k | 7.1e-06 7.8e-05 9.7e-06 8.7e-05 4.0e-04 |\n|  PF2 |  11k  17k | 8.7e-06 1.5e-03 1.8e-05 1.4e-03 7.6e-03 |\n|  PF3 |  86k 131k | 1.3e-04 1.9e-03 2.2e-04 2.3e-03 9.2e-03 |\n==============================================================\n|      |           |           ExaModels (gpu)               |\n| case | nvar ncon |   obj     con    grad     jac    hess   |\n==============================================================\n|  LV1 | 100   98  | 8.3e-05 4.8e-05 8.9e-05 5.3e-05 1.1e-04 |\n|  LV2 |   1k 998  | 5.1e-05 2.6e-05 5.4e-05 3.7e-05 6.6e-05 |\n|  LV3 |  10k  10k | 6.4e-05 2.8e-05 5.7e-05 3.5e-05 6.8e-05 |\n|  QR1 | 659  459  | 1.1e-04 2.2e-04 1.0e-04 2.3e-04 3.2e-04 |\n|  QR2 |   7k   5k | 9.1e-05 1.5e-04 8.3e-05 1.6e-04 2.3e-04 |\n|  QR3 |  65k  45k | 1.0e-04 1.7e-04 9.0e-05 1.8e-04 2.6e-04 |\n|  DC1 | 402  396  | 8.3e-05 2.0e-04 7.9e-05 2.0e-04 2.6e-04 |\n|  DC2 |   3k   3k | 6.6e-05 1.6e-04 6.7e-05 1.6e-04 2.1e-04 |\n|  DC3 |  34k  33k | 7.3e-05 1.6e-04 7.0e-05 1.7e-04 2.5e-04 |\n|  PF1 |   1k   2k | 5.7e-05 3.4e-04 5.2e-05 2.8e-04 3.5e-04 |\n|  PF2 |  11k  17k | 5.6e-05 3.2e-04 5.6e-05 3.1e-04 3.1e-04 |\n|  PF3 |  86k 131k | 9.9e-05 3.6e-04 5.0e-05 2.9e-04 3.8e-04 |\n==============================================================\n|      |           |                  JuMP                   |\n| case | nvar ncon |   obj     con    grad     jac    hess   |\n==============================================================\n|  LV1 | 100   98  | 5.5e-06 2.8e-05 8.6e-06 3.1e-05 3.5e-04 |\n|  LV2 |   1k 998  | 4.6e-05 2.9e-04 1.1e-04 4.9e-04 2.9e-03 |\n|  LV3 |  10k  10k | 9.1e-04 4.8e-03 2.1e-03 7.0e-03 2.5e-02 |\n|  QR1 | 659  459  | 9.2e-06 3.1e-05 8.3e-06 5.1e-05 1.0e-04 |\n|  QR2 |   7k   5k | 1.2e-04 3.7e-04 1.1e-04 7.0e-04 3.8e-03 |\n|  QR3 |  65k  45k | 2.1e-03 8.2e-03 2.1e-03 1.6e-02 4.0e-02 |\n|  DC1 | 402  396  | 2.5e-06 2.0e-05 4.1e-06 3.9e-05 3.5e-04 |\n|  DC2 |   3k   3k | 2.7e-05 2.9e-04 6.0e-05 6.0e-04 1.2e-03 |\n|  DC3 |  34k  33k | 4.8e-04 7.7e-03 1.9e-03 1.5e-02 4.2e-02 |\n|  PF1 |   1k   2k | 3.5e-06 1.1e-04 4.0e-06 2.3e-04 1.9e-03 |\n|  PF2 |  11k  17k | 3.8e-05 2.1e-03 5.0e-05 4.4e-03 1.7e-02 |\n|  PF3 |  86k 131k | 6.9e-04 3.5e-02 1.1e-03 7.2e-02 1.1e-01 | \n==============================================================\n|      |           |                  AMPL                   |\n| case | nvar ncon |   obj     con    grad     jac    hess   |\n==============================================================\n|  LV1 | 100   98  | 1.2e-06 1.7e-06 9.1e-06 1.3e-05 2.1e-04 |\n|  LV2 |   1k 998  | 1.5e-06 8.5e-06 2.6e-05 1.7e-04 1.6e-03 |\n|  LV3 |  10k  10k | 8.9e-06 2.3e-04 3.1e-04 3.4e-03 2.2e-02 |\n|  QR1 | 659  459  | 1.5e-06 3.4e-06 1.4e-06 2.7e-05 2.9e-04 |\n|  QR2 |   7k   5k | 1.2e-05 4.5e-05 1.2e-05 3.5e-04 4.4e-03 |\n|  QR3 |  65k  45k | 1.4e-04 1.1e-03 1.2e-04 7.9e-03 5.4e-02 |\n|  DC1 | 402  396  | 5.3e-07 4.8e-06 1.2e-06 5.2e-06 3.5e-05 |\n|  DC2 |   3k   3k | 8.6e-07 3.9e-05 5.5e-06 6.2e-05 2.6e-05 |\n|  DC3 |  34k  33k | 4.8e-06 4.1e-04 2.5e-05 4.1e-04 3.3e-03 |\n|  PF1 |   1k   2k | 9.5e-07 2.4e-04 2.8e-06 1.3e-04 1.6e-03 |\n|  PF2 |  11k  17k | 1.1e-06 5.1e-03 7.7e-06 3.5e-03 2.6e-02 |\n|  PF3 |  86k 131k | 3.5e-06 4.1e-02 5.4e-05 3.6e-02 2.3e-01 |\n==============================================================\n * commit : 8a396718b7f7632d239e9edb18f6177fedf4e2a0\n * CPU    : Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz (nthreads = 20)\n * GPU    : Quadro GV100","category":"page"},{"location":"simd/#SIMD-Abstraction","page":"Mathematical Abstraction","title":"SIMD Abstraction","text":"","category":"section"},{"location":"simd/","page":"Mathematical Abstraction","title":"Mathematical Abstraction","text":"In this page, we explain what SIMD abstraction of nonlinear program is, and why it can be beneficial for scalable optimization of large-scale optimization problems. More discussion can be found in our paper.","category":"page"},{"location":"simd/#What-is-SIMD-abstraction?","page":"Mathematical Abstraction","title":"What is SIMD abstraction?","text":"","category":"section"},{"location":"simd/","page":"Mathematical Abstraction","title":"Mathematical Abstraction","text":"The mathematical statement of the problem formulation is as follows.","category":"page"},{"location":"simd/","page":"Mathematical Abstraction","title":"Mathematical Abstraction","text":"beginaligned\n  min_x^flatleq x leq x^sharp\n   sum_linLsum_iin I_l f^(l)(x p^(l)_i)\n  textst leftg^(m)(x q_j)right_jin J_m +sum_nin N_msum_kin K_nh^(n)(x s^(n)_k) =0quad forall minM\nendaligned","category":"page"},{"location":"simd/","page":"Mathematical Abstraction","title":"Mathematical Abstraction","text":"where f^(ell)(cdotcdot), g^(m)(cdotcdot), and h^(n)(cdotcdot) are twice differentiable functions with respect to the first argument, whereas p^(k)_i_iin N_k_kinK, q^(k)_i_iin M_l_minM, and s^(n)_k_kinK_n_ninN_m_minM are problem data, which can either be discrete or continuous. It is also assumed that our functions f^(l)(cdotcdot), g^(m)(cdotcdot), and h^(n)(cdotcdot) can be expressed with computational graphs of moderate length. ","category":"page"},{"location":"simd/#Why-SIMD-abstraction?","page":"Mathematical Abstraction","title":"Why SIMD abstraction?","text":"","category":"section"},{"location":"simd/","page":"Mathematical Abstraction","title":"Mathematical Abstraction","text":"Many physics-based models, such as AC OPF, have a highly repetitive structure. One of the manifestations of it is that the mathematical statement of the model is concise, even if the practical model may contain millions of variables and constraints. This is possible due to the use of repetition over a certain index and data sets. For example, it suffices to use 15 computational patterns to fully specify the AC OPF model. These patterns arise from (1) generation cost, (2) reference bus voltage angle constraint, (3-6) active and reactive power flow (from and to), (7) voltage angle difference constraint, (8-9) apparent power flow limits (from and to), (10-11) power balance equations, (12-13) generators' contributions to the power balance equations, and (14-15) in/out flows contributions to the power balance equations. However, such repetitive structure is not well exploited in the standard NLP modeling paradigms. In fact, without the SIMD abstraction, it is difficult for the AD package to detect the parallelizable structure within the model, as it will require the full inspection of the computational graph over all expressions.  By preserving the repetitive structures in the model, the repetitive structure can be directly available in AD implementation.","category":"page"},{"location":"simd/","page":"Mathematical Abstraction","title":"Mathematical Abstraction","text":"Using the multiple dispatch feature of Julia, ExaModels.jl generates highly efficient derivative computation code, specifically compiled for each computational pattern in the model. These derivative evaluation codes can be run over the data in various GPU array formats, and implemented via array and kernel programming in Julia Language. In turn, ExaModels.jl has the capability to efficiently evaluate first and second-order derivatives using GPU accelerators.","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"EditURL = \"gpu.jl\"","category":"page"},{"location":"gpu/#Accelerations","page":"Accelerations","title":"Accelerations","text":"","category":"section"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"One of the key features of ExaModels.jl is being able to evaluate derivatives either on multi-threaded CPUs or GPU accelerators. Currently, GPU acceleration is only tested for NVIDIA GPUs. If you'd like to use multi-threaded CPU acceleration, start julia with","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"$ julia -t 4 # using 4 threads","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"Also, if you're using NVIDIA GPUs, make sure to have installed appropriate drivers.","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"Let's say that our CPU code is as follows.","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"function luksan_vlcek_obj(x,i)\n    return 100*(x[i-1]^2-x[i])^2+(x[i-1]-1)^2\nend\n\nfunction luksan_vlcek_con(x,i)\n    return 3x[i+1]^3+2*x[i+2]-5+sin(x[i+1]-x[i+2])sin(x[i+1]+x[i+2])+4x[i+1]-x[i]exp(x[i]-x[i+1])-3\nend\n\nfunction luksan_vlcek_x0(i)\n    return mod(i,2)==1 ? -1.2 : 1.0\nend\n\nfunction luksan_vlcek_model(N)\n\n    c = ExaCore()\n    x = variable(\n        c, N;\n        start = (luksan_vlcek_x0(i) for i=1:N)\n    )\n    constraint(\n        c,\n        luksan_vlcek_con(x,i)\n        for i in 1:N-2)\n    objective(\n        c,\n        luksan_vlcek_obj(x,i)\n        for i in 2:N)\n\n    return ExaModel(c)\nend","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"luksan_vlcek_model (generic function with 1 method)","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"Now we simply modify this by","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"function luksan_vlcek_model(N, backend = nothing)\n\n    c = ExaCore(backend) # specify the backend\n    x = variable(\n        c, N;\n        start = (luksan_vlcek_x0(i) for i=1:N)\n    )\n    constraint(\n        c,\n        luksan_vlcek_con(x,i)\n        for i in 1:N-2)\n    objective(\n        c,\n        luksan_vlcek_obj(x,i)\n        for i in 2:N)\n\n    return ExaModel(c)\nend","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"luksan_vlcek_model (generic function with 2 methods)","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"The acceleration can be done simply by specifying the backend. In particular, for multi-threaded CPUs,","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"using ExaModels, NLPModelsIpopt, KernelAbstractions\n\nm = luksan_vlcek_model(10, CPU())\nipopt(m)","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"For NVIDIA GPUs, we can use CUDABackend. However, currently, there are not many optimization solvers that are capable of solving problems on GPUs. The only option right now is using a development branch in MadNLP.jl. To use this, first install","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"import Pkg; Pkg.add(name = \"MadNLP\", rev=\"ss/sparse_condensed_2\")","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"Then, we can run:","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"using CUDA, MadNLP, MadNLPGPU\n\nm = luksan_vlcek_model(10, CUDABackend())\nmadnlp(m)","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"In the case we have arrays for the data, what we need to do is to simply convert the array types to the corresponding device array types. In particular,","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"function cuda_luksan_vlcek_model(N)\n    c = ExaCore(CUDABackend())\n    d1 = CuArray(1:N-2)\n    d2 = CuArray(2:N)\n    d3 = CuArray([luksan_vlcek_x0(i) for i=1:N])\n\n    x = variable(\n        c, N;\n        start = d3\n    )\n    constraint(\n        c,\n        luksan_vlcek_con(x,i)\n        for i in d1\n    )\n    objective(\n        c,\n        luksan_vlcek_obj(x,i)\n        for i in d2\n    )\n\n    return ExaModel(c)\nend","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"cuda_luksan_vlcek_model (generic function with 1 method)","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"m = cuda_luksan_vlcek_model(10)\nmadnlp(m)","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"","category":"page"},{"location":"gpu/","page":"Accelerations","title":"Accelerations","text":"This page was generated using Literate.jl.","category":"page"},{"location":"ref/#References","page":"References","title":"References","text":"","category":"section"},{"location":"ref/","page":"References","title":"References","text":"","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Welcome to the documentation of ExaModels.jl\t","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"note: Note\nThis documentation is also available in PDF format: ExaModels.pdf.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"warning: Warning\nThis documentation page is currently under construction. Please help us improve ExaModels.jl and this documentation! ExaModels.jl is in the early stage of development, and you may encounter unintended behaviors or missing documentations. If you find anything is not working as intended or documentation is missing, please open issues or pull requests or start discussions. ","category":"page"},{"location":"#What-is-ExaModels.jl?","page":"Overview","title":"What is ExaModels.jl?","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ExaModels.jl is an algebraic modeling and automatic differentiation tool in Julia Language, specialized for SIMD abstraction of nonlinear programs. ExaModels.jl employs what we call SIMD abstraction for nonlinear programs (NLPs), which allows for the preservation of the parallelizable structure within the model equations, facilitating efficient automatic differentiation either on the single-thread CPUs, multi-threaded CPUs, as well as GPU accelerators. More details about SIMD abstraction can be found here.","category":"page"},{"location":"#When-should-I-use-ExaModels.jl?","page":"Overview","title":"When should I use ExaModels.jl?","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ExaModels.jl shines when your model has","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"nonlinear objective and constraints;\na large number of variables and constraints;\nhighly repetitive structure;\nsparse Hessian and Jacobian.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"These features are often exhibited in optimization problems associated with first-principle physics-based models. Primary examples include optimal control problems formulated with direct subscription method [1] and network system optimization problems, such as optimal power flow [2] and gas network control/estimation problems.","category":"page"},{"location":"#New-to-Julia?","page":"Overview","title":"New to Julia?","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Welcome to Julia community! Below is the helpful link to start using Julia.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"juliaup: julia installer and version multiplexer.\nJulia tutorial in Julia's official documentation.","category":"page"},{"location":"#Supported-Solvers","page":"Overview","title":"Supported Solvers","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ExaModels can be used with any solver that can handle NLPModel data type, but several callbacks are not currently implemented, and cause some errors. Currently, it is tested with the following solvers:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Ipopt (via NLPModelsIpopt.jl)\nMadNLP.jl","category":"page"},{"location":"#Documentation-Structure","page":"Overview","title":"Documentation Structure","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"This documentation is structured in the following way.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The remainder of this page highlights several key aspects of ExaModels.jl.\nThe mathematical abstraction–-SIMD abstraction of nonlinear programming–-of ExaModels.jl is discussed in Mathematical Abstraction page.\nThe step-by-step tutorial of using ExaModels.jl can be found in Tutorial page.\nThis documentation does not intend to discuss the engineering behind the implementation of ExaModels.jl. Some high-level idea is discussed in a recent publication, but the full details of the engineering behind it will be discussed in the future publications.","category":"page"},{"location":"#Citing-ExaModels.jl","page":"Overview","title":"Citing ExaModels.jl","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"If you use ExaModels.jl in your research, we would greatly appreciate your citing this preprint.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"@misc{shin2023accelerating,\n      title={Accelerating Optimal Power Flow with {GPU}s: {SIMD} Abstraction of Nonlinear Programs and Condensed-Space Interior-Point Methods}, \n      author={Sungho Shin and Fran{\\c{c}}ois Pacaud and Mihai Anitescu},\n      year={2023},\n      eprint={2307.16830},\n      archivePrefix={arXiv},\n      primaryClass={math.OC}\n}","category":"page"},{"location":"#Supporting-ExaModels.jl","page":"Overview","title":"Supporting ExaModels.jl","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Please report issues and feature requests via the GitHub issue tracker.\nQuestions are welcome at GitHub discussion forum.","category":"page"}]
}
